import React, { useState, useRef, useEffect } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  Alert,
  Animated,
  Dimensions,
} from 'react-native';
import { Audio } from 'expo-av';
import { Colors } from '../constants/colors';
import { Typography } from '../constants/typography';
import { Spacing } from '../constants/spacing';

interface VoiceRecorderProps {
  onRecordingComplete: (audioData: string, duration: number) => void;
  onRecordingStart?: () => void;
  onRecordingStop?: () => void;
  disabled?: boolean;
  maxDuration?: number; // ìµœëŒ€ ë…¹ìŒ ì‹œê°„ (milliseconds)
  minDuration?: number; // ìµœì†Œ ë…¹ìŒ ì‹œê°„ (milliseconds)
}

interface RecordingState {
  isRecording: boolean;
  isPreparing: boolean;
  duration: number;
  hasPermission: boolean;
}

const VoiceRecorder: React.FC<VoiceRecorderProps> = ({
  onRecordingComplete,
  onRecordingStart,
  onRecordingStop,
  disabled = false,
  maxDuration = 60000, // 1ë¶„
  minDuration = 1000,  // 1ì´ˆ
}) => {
  const [state, setState] = useState<RecordingState>({
    isRecording: false,
    isPreparing: false,
    duration: 0,
    hasPermission: false,
  });

  const recordingRef = useRef<Audio.Recording | null>(null);
  const durationTimerRef = useRef<NodeJS.Timeout | null>(null);
  
  // ì• ë‹ˆë©”ì´ì…˜
  const pulseAnim = useRef(new Animated.Value(1)).current;
  const waveAnim = useRef(new Animated.Value(0)).current;

  // ê¶Œí•œ ìš”ì²­
  const requestPermissions = async (): Promise<boolean> => {
    try {
      const { status } = await Audio.requestPermissionsAsync();
      const hasPermission = status === 'granted';
      setState(prev => ({ ...prev, hasPermission }));
      
      if (!hasPermission) {
        Alert.alert(
          'ë§ˆì´í¬ ê¶Œí•œ í•„ìš”',
          'ìŒì„± ë…¹ìŒì„ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
          [{ text: 'í™•ì¸' }]
        );
      }
      
      return hasPermission;
    } catch (error) {
      console.error('Permission request failed:', error);
      return false;
    }
  };

  // ë…¹ìŒ ì„¤ì •
  const configureAudio = async () => {
    try {
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        playThroughEarpieceAndroid: false,
        staysActiveInBackground: false,
      });
    } catch (error) {
      console.error('Audio configuration failed:', error);
    }
  };

  // ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    if (disabled || state.isRecording) return;

    setState(prev => ({ ...prev, isPreparing: true }));

    try {
      // ê¶Œí•œ í™•ì¸
      if (!state.hasPermission) {
        const hasPermission = await requestPermissions();
        if (!hasPermission) {
          setState(prev => ({ ...prev, isPreparing: false }));
          return;
        }
      }

      // ì˜¤ë””ì˜¤ ì„¤ì •
      await configureAudio();

      // ê¸°ì¡´ ë…¹ìŒ ì •ë¦¬
      if (recordingRef.current) {
        await recordingRef.current.stopAndUnloadAsync();
        recordingRef.current = null;
      }

      // ìƒˆ ë…¹ìŒ ì‹œì‘
      const recording = new Audio.Recording();
      await recording.prepareToRecordAsync({
        android: {
          extension: '.wav',
          outputFormat: Audio.AndroidOutputFormat.DEFAULT,
          audioEncoder: Audio.AndroidAudioEncoder.DEFAULT,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
        },
        ios: {
          extension: '.wav',
          outputFormat: Audio.IOSOutputFormat.LINEARPCM,
          audioQuality: Audio.IOSAudioQuality.HIGH,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
      });

      await recording.startAsync();
      recordingRef.current = recording;

      // ìƒíƒœ ì—…ë°ì´íŠ¸
      setState(prev => ({
        ...prev,
        isRecording: true,
        isPreparing: false,
        duration: 0,
      }));

      // ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
      startPulseAnimation();
      startWaveAnimation();

      // ë…¹ìŒ ì‹œê°„ ì¹´ìš´í„° ì‹œì‘
      durationTimerRef.current = setInterval(() => {
        setState(prev => {
          const newDuration = prev.duration + 100;
          
          // ìµœëŒ€ ì‹œê°„ ì´ˆê³¼ ì‹œ ìë™ ì¤‘ì§€
          if (newDuration >= maxDuration) {
            stopRecording();
            return prev;
          }
          
          return { ...prev, duration: newDuration };
        });
      }, 100);

      onRecordingStart?.();

    } catch (error) {
      console.error('Recording start failed:', error);
      setState(prev => ({ ...prev, isPreparing: false, isRecording: false }));
      Alert.alert('ë…¹ìŒ ì˜¤ë¥˜', 'ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = async () => {
    if (!state.isRecording || !recordingRef.current) return;

    try {
      // íƒ€ì´ë¨¸ ì •ë¦¬
      if (durationTimerRef.current) {
        clearInterval(durationTimerRef.current);
        durationTimerRef.current = null;
      }

      // ì• ë‹ˆë©”ì´ì…˜ ì¤‘ì§€
      stopPulseAnimation();
      stopWaveAnimation();

      // ë…¹ìŒ ì¤‘ì§€
      await recordingRef.current.stopAndUnloadAsync();
      const uri = recordingRef.current.getURI();
      
      setState(prev => ({ ...prev, isRecording: false }));
      
      if (uri) {
        // ìµœì†Œ ë…¹ìŒ ì‹œê°„ í™•ì¸
        if (state.duration < minDuration) {
          Alert.alert(
            'ë…¹ìŒ ì‹œê°„ ë¶€ì¡±', 
            `ìµœì†Œ ${Math.ceil(minDuration / 1000)}ì´ˆ ì´ìƒ ë…¹ìŒí•´ì£¼ì„¸ìš”.`
          );
          setState(prev => ({ ...prev, duration: 0 }));
          return;
        }

        // ì˜¤ë””ì˜¤ íŒŒì¼ì„ Base64ë¡œ ë³€í™˜
        try {
          const response = await fetch(uri);
          const blob = await response.blob();
          const base64Data = await new Promise<string>((resolve) => {
            const reader = new FileReader();
            reader.onloadend = () => {
              const base64 = reader.result as string;
              resolve(base64);
            };
            reader.readAsDataURL(blob);
          });

          onRecordingComplete(base64Data, state.duration);
          onRecordingStop?.();
        } catch (error) {
          console.error('Audio conversion failed:', error);
          Alert.alert('ë³€í™˜ ì˜¤ë¥˜', 'ë…¹ìŒ íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        }
      }

      recordingRef.current = null;
      setState(prev => ({ ...prev, duration: 0 }));

    } catch (error) {
      console.error('Recording stop failed:', error);
      Alert.alert('ë…¹ìŒ ì˜¤ë¥˜', 'ë…¹ìŒì„ ì¤‘ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  // í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜
  const startPulseAnimation = () => {
    const pulse = () => {
      Animated.sequence([
        Animated.timing(pulseAnim, {
          toValue: 1.2,
          duration: 800,
          useNativeDriver: true,
        }),
        Animated.timing(pulseAnim, {
          toValue: 1,
          duration: 800,
          useNativeDriver: true,
        }),
      ]).start((finished) => {
        if (finished && state.isRecording) {
          pulse();
        }
      });
    };
    pulse();
  };

  const stopPulseAnimation = () => {
    pulseAnim.setValue(1);
  };

  // ì›¨ì´ë¸Œ ì• ë‹ˆë©”ì´ì…˜
  const startWaveAnimation = () => {
    const wave = () => {
      Animated.timing(waveAnim, {
        toValue: 1,
        duration: 1500,
        useNativeDriver: true,
      }).start((finished) => {
        if (finished && state.isRecording) {
          waveAnim.setValue(0);
          wave();
        }
      });
    };
    wave();
  };

  const stopWaveAnimation = () => {
    waveAnim.setValue(0);
  };

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ê¶Œí•œ í™•ì¸
  useEffect(() => {
    requestPermissions();
    
    return () => {
      // ì •ë¦¬
      if (durationTimerRef.current) {
        clearInterval(durationTimerRef.current);
      }
      if (recordingRef.current) {
        recordingRef.current.stopAndUnloadAsync();
      }
    };
  }, []);

  // ì‹œê°„ í¬ë§·íŒ…
  const formatDuration = (ms: number): string => {
    const seconds = Math.floor(ms / 1000);
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  };

  const maxDurationSeconds = Math.floor(maxDuration / 1000);

  return (
    <View style={styles.container}>
      {/* ë…¹ìŒ ë²„íŠ¼ */}
      <TouchableOpacity
        style={[
          styles.recordButton,
          state.isRecording && styles.recordButtonActive,
          disabled && styles.recordButtonDisabled,
        ]}
        onPress={state.isRecording ? stopRecording : startRecording}
        disabled={disabled || state.isPreparing}
        activeOpacity={0.7}
      >
        <Animated.View
          style={[
            styles.recordButtonInner,
            { transform: [{ scale: state.isRecording ? pulseAnim : 1 }] }
          ]}
        >
          <Text style={[
            styles.recordButtonText,
            state.isRecording && styles.recordButtonTextActive
          ]}>
            {state.isPreparing ? 'ğŸ”„' : state.isRecording ? 'ğŸ”´' : 'ğŸ¤'}
          </Text>
        </Animated.View>

        {/* ë…¹ìŒ ì¤‘ íŒŒí˜• íš¨ê³¼ */}
        {state.isRecording && (
          <Animated.View
            style={[
              styles.waveEffect,
              {
                transform: [{
                  scale: waveAnim.interpolate({
                    inputRange: [0, 1],
                    outputRange: [1, 1.5],
                  })
                }],
                opacity: waveAnim.interpolate({
                  inputRange: [0, 1],
                  outputRange: [0.6, 0],
                }),
              }
            ]}
          />
        )}
      </TouchableOpacity>

      {/* ìƒíƒœ í…ìŠ¤íŠ¸ */}
      <View style={styles.statusContainer}>
        <Text style={styles.statusText}>
          {state.isPreparing ? 'ì¤€ë¹„ ì¤‘...' :
           state.isRecording ? `ğŸ”´ ë…¹ìŒ ì¤‘ ${formatDuration(state.duration)}` :
           'ìŒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒí•˜ì„¸ìš”'}
        </Text>
        
        {state.isRecording && (
          <Text style={styles.maxDurationText}>
            ìµœëŒ€ {maxDurationSeconds}ì´ˆ
          </Text>
        )}
      </View>

      {/* ì§„í–‰ ë°” */}
      {state.isRecording && (
        <View style={styles.progressBarContainer}>
          <View
            style={[
              styles.progressBar,
              { width: `${(state.duration / maxDuration) * 100}%` }
            ]}
          />
        </View>
      )}
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    alignItems: 'center',
    paddingVertical: Spacing.lg,
  },
  recordButton: {
    width: 80,
    height: 80,
    borderRadius: 40,
    backgroundColor: Colors.accent.main,
    justifyContent: 'center',
    alignItems: 'center',
    elevation: 4,
    shadowColor: Colors.shadow,
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.25,
    shadowRadius: 4,
    marginBottom: Spacing.md,
  },
  recordButtonActive: {
    backgroundColor: Colors.status.error,
  },
  recordButtonDisabled: {
    backgroundColor: Colors.background.tertiary,
    opacity: 0.6,
  },
  recordButtonInner: {
    width: '100%',
    height: '100%',
    justifyContent: 'center',
    alignItems: 'center',
    borderRadius: 40,
  },
  recordButtonText: {
    fontSize: 32,
  },
  recordButtonTextActive: {
    fontSize: 28,
  },
  waveEffect: {
    position: 'absolute',
    width: 80,
    height: 80,
    borderRadius: 40,
    borderWidth: 2,
    borderColor: Colors.status.error,
  },
  statusContainer: {
    alignItems: 'center',
    minHeight: 50,
  },
  statusText: {
    ...typography.body,
    color: Colors.text.primary,
    textAlign: 'center',
    marginBottom: Spacing.xs,
  },
  maxDurationText: {
    ...typography.caption,
    color: Colors.text.secondary,
  },
  progressBarContainer: {
    width: Dimensions.get('window').width * 0.7,
    height: 4,
    backgroundColor: Colors.background.tertiary,
    borderRadius: 2,
    marginTop: Spacing.md,
  },
  progressBar: {
    height: '100%',
    backgroundColor: Colors.status.error,
    borderRadius: 2,
  },
});

export default VoiceRecorder;
"""
ì•ˆì „í•œ ë¬¸ì œ ì—…ë¡œë“œ ì‹œìŠ¤í…œ
ì´ë¯¸ ê²€ì¦ëœ ë¬¸ì œë“¤ì˜ ë°ì´í„° ë¬´ê²°ì„±ì„ ë³´ì¥í•˜ëŠ” ì—…ë¡œë“œ ë„êµ¬
"""

import streamlit as st
import pandas as pd
import json
import hashlib
from datetime import datetime
import difflib

class SecureUploader:
    """ì•ˆì „í•œ ì—…ë¡œë“œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.upload_log = []
        
    def calculate_question_hash(self, question_data):
        """ë¬¸ì œ ë°ì´í„°ì˜ í•´ì‹œê°’ ê³„ì‚° (ë¬´ê²°ì„± ê²€ì¦ìš©)"""
        # ì¤‘ìš”í•œ í•„ë“œë“¤ë§Œ í•´ì‹œ ê³„ì‚°
        key_data = {
            'question': question_data.get('question', ''),
            'options': question_data.get('options', []),
            'correct_answer': question_data.get('correct_answer', -1),
            'explanation': question_data.get('explanation', '')
        }
        
        # ì •ê·œí™”ëœ ë¬¸ìì—´ë¡œ ë³€í™˜
        normalized = json.dumps(key_data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(normalized.encode('utf-8')).hexdigest()
    
    def validate_upload_integrity(self, df):
        """ì—…ë¡œë“œ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        integrity_issues = []
        processed_questions = []
        
        for index, row in df.iterrows():
            try:
                # ë°ì´í„° ì¶”ì¶œ
                question_data = {
                    'id': str(row['ë¬¸ì œID']).strip(),
                    'question': str(row['ë¬¸ì œ']).strip(),
                    'options': [
                        str(row['ì„ íƒì§€1']).strip(),
                        str(row['ì„ íƒì§€2']).strip(),
                        str(row['ì„ íƒì§€3']).strip(),
                        str(row['ì„ íƒì§€4']).strip()
                    ],
                    'correct_answer': int(row['ì •ë‹µ']) - 1,
                    'explanation': str(row['í•´ì„¤']).strip(),
                    'category': str(row['ì¹´í…Œê³ ë¦¬']).strip(),
                    'difficulty': str(row['ë‚œì´ë„']).strip(),
                    'year': str(row['ì—°ë„']).strip(),
                    'round': str(row['íšŒì°¨']).strip()
                }
                
                # ë¬´ê²°ì„± ê²€ì‚¬
                issues = self._check_data_integrity(question_data, index + 1)
                if issues:
                    integrity_issues.extend(issues)
                else:
                    processed_questions.append(question_data)
                    
            except Exception as e:
                integrity_issues.append({
                    'row': index + 1,
                    'type': 'ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜',
                    'message': str(e),
                    'severity': 'ERROR'
                })
        
        return processed_questions, integrity_issues
    
    def _check_data_integrity(self, question_data, row_num):
        """ê°œë³„ ë¬¸ì œ ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬"""
        issues = []
        
        # 1. ì •ë‹µ ë²”ìœ„ ê²€ì¦
        if not 0 <= question_data['correct_answer'] <= 3:
            issues.append({
                'row': row_num,
                'type': 'ì •ë‹µ ì˜¤ë¥˜',
                'message': f"ì •ë‹µì´ ì˜ëª»ë¨: {question_data['correct_answer'] + 1}ë²ˆ (1-4 ë²”ìœ„ ë²—ì–´ë‚¨)",
                'severity': 'ERROR'
            })
        
        # 2. ì„ íƒì§€ ê°œìˆ˜ ê²€ì¦
        if len(question_data['options']) != 4:
            issues.append({
                'row': row_num,
                'type': 'ì„ íƒì§€ ì˜¤ë¥˜',
                'message': f"ì„ íƒì§€ ê°œìˆ˜ ì˜¤ë¥˜: {len(question_data['options'])}ê°œ (4ê°œ í•„ìš”)",
                'severity': 'ERROR'
            })
        
        # 3. ë¹ˆ ì„ íƒì§€ ê²€ì¦
        for i, option in enumerate(question_data['options']):
            if not option or len(option) < 2:
                issues.append({
                    'row': row_num,
                    'type': 'ì„ íƒì§€ ì˜¤ë¥˜',
                    'message': f"ì„ íƒì§€ {i+1}ë²ˆì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŒ",
                    'severity': 'ERROR'
                })
        
        # 4. ì¤‘ë³µ ì„ íƒì§€ ê²€ì¦
        if len(set(question_data['options'])) != 4:
            issues.append({
                'row': row_num,
                'type': 'ì„ íƒì§€ ì¤‘ë³µ',
                'message': "ì¤‘ë³µëœ ì„ íƒì§€ê°€ ìˆìŒ",
                'severity': 'ERROR'
            })
        
        # 5. ë¬¸ì œ ë‚´ìš© ê²€ì¦
        if len(question_data['question']) < 10:
            issues.append({
                'row': row_num,
                'type': 'ë¬¸ì œ ë‚´ìš© ì˜¤ë¥˜',
                'message': "ë¬¸ì œê°€ ë„ˆë¬´ ì§§ìŒ",
                'severity': 'WARNING'
            })
        
        # 6. í•´ì„¤ ê²€ì¦
        if len(question_data['explanation']) < 5:
            issues.append({
                'row': row_num,
                'type': 'í•´ì„¤ ì˜¤ë¥˜',
                'message': "í•´ì„¤ì´ ë„ˆë¬´ ì§§ìŒ",
                'severity': 'WARNING'
            })
        
        # 7. ì¸ì½”ë”© ë¬¸ì œ ê²€ì¦
        try:
            for field in ['question', 'explanation']:
                if question_data[field].encode('utf-8').decode('utf-8') != question_data[field]:
                    issues.append({
                        'row': row_num,
                        'type': 'ì¸ì½”ë”© ì˜¤ë¥˜',
                        'message': f"{field} í•„ë“œì— ì¸ì½”ë”© ë¬¸ì œ ìˆìŒ",
                        'severity': 'WARNING'
                    })
        except UnicodeError:
            issues.append({
                'row': row_num,
                'type': 'ì¸ì½”ë”© ì˜¤ë¥˜',
                'message': "í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì˜¤ë¥˜",
                'severity': 'ERROR'
            })
        
        return issues
    
    def create_backup(self):
        """ê¸°ì¡´ DB ë°±ì—…"""
        try:
            with open("real_past_questions_db.json", 'r', encoding='utf-8') as f:
                db_data = json.load(f)
            
            backup_filename = f"backup_questions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(backup_filename, 'w', encoding='utf-8') as f:
                json.dump(db_data, f, ensure_ascii=False, indent=2)
            
            return backup_filename
        except FileNotFoundError:
            return None
    
    def compare_with_existing(self, new_questions):
        """ê¸°ì¡´ ë¬¸ì œì™€ ì¤‘ë³µ ê²€ì‚¬"""
        try:
            with open("real_past_questions_db.json", 'r', encoding='utf-8') as f:
                db_data = json.load(f)
            
            existing_ids = set(q['id'] for q in db_data.get('questions', []))
            duplicate_ids = [q['id'] for q in new_questions if q['id'] in existing_ids]
            
            return duplicate_ids
        except FileNotFoundError:
            return []

def main():
    st.title("ğŸ”’ ì•ˆì „í•œ ë¬¸ì œ ì—…ë¡œë“œ ì‹œìŠ¤í…œ")
    st.markdown("""
    **ì´ë¯¸ ê²€ì¦ëœ ë¬¸ì œë“¤ì˜ ë°ì´í„° ë¬´ê²°ì„±ì„ ë³´ì¥**í•˜ë©° ì•ˆì „í•˜ê²Œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    
    âœ… **ë³´ì¥ì‚¬í•­:**
    - ì—…ë¡œë“œ ê³¼ì •ì—ì„œ ì •ë‹µ ë³€ê²½ ë°©ì§€
    - ì„ íƒì§€ ìˆœì„œ ë³´ì¡´
    - í…ìŠ¤íŠ¸ ì¸ì½”ë”© ë³´ì¥
    - ë°ì´í„° ì†ì‹¤ ë°©ì§€
    """)
    
    uploader = SecureUploader()
    
    # 1ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ
    st.header("1ï¸âƒ£ ê²€ì¦ëœ ë¬¸ì œ íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['csv'],
        help="ì´ë¯¸ ê²€ì¦ì´ ì™„ë£Œëœ ë¬¸ì œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_file:
        try:
            # íŒŒì¼ ì½ê¸° (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)
            encodings = ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']
            df = None
            used_encoding = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    used_encoding = encoding
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                st.error("âŒ íŒŒì¼ ì¸ì½”ë”©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            st.success(f"âœ… íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤. (ì¸ì½”ë”©: {used_encoding})")
            
            # 2ë‹¨ê³„: íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
            st.header("2ï¸âƒ£ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df.head())
            st.info(f"ì´ {len(df)}ê°œ ë¬¸ì œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            
            # 3ë‹¨ê³„: í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            st.header("3ï¸âƒ£ ë°ì´í„° êµ¬ì¡° ê²€ì¦")
            
            required_cols = ['ë¬¸ì œID', 'ì¹´í…Œê³ ë¦¬', 'ë‚œì´ë„', 'ì—°ë„', 'íšŒì°¨', 'ë¬¸ì œ', 
                           'ì„ íƒì§€1', 'ì„ íƒì§€2', 'ì„ íƒì§€3', 'ì„ íƒì§€4', 'ì •ë‹µ', 'í•´ì„¤']
            
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
                st.stop()
            else:
                st.success("âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
            
            # 4ë‹¨ê³„: ë¬´ê²°ì„± ê²€ì¦
            if st.button("ğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹œì‘"):
                st.header("4ï¸âƒ£ ë¬´ê²°ì„± ê²€ì¦ ê²°ê³¼")
                
                with st.spinner("ë°ì´í„° ë¬´ê²°ì„±ì„ ê²€ì¦í•˜ëŠ” ì¤‘..."):
                    processed_questions, integrity_issues = uploader.validate_upload_integrity(df)
                
                # ê²°ê³¼ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ ë¬¸ì œ", len(df))
                with col2:
                    st.metric("âœ… í†µê³¼", len(processed_questions))
                with col3:
                    error_count = len([issue for issue in integrity_issues if issue['severity'] == 'ERROR'])
                    st.metric("âŒ ì˜¤ë¥˜", error_count)
                
                # ì˜¤ë¥˜ í‘œì‹œ
                if integrity_issues:
                    error_issues = [issue for issue in integrity_issues if issue['severity'] == 'ERROR']
                    warning_issues = [issue for issue in integrity_issues if issue['severity'] == 'WARNING']
                    
                    if error_issues:
                        st.error(f"âŒ {len(error_issues)}ê°œì˜ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
                        for issue in error_issues:
                            st.write(f"- í–‰ {issue['row']}: [{issue['type']}] {issue['message']}")
                        st.warning("âš ï¸ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    
                    if warning_issues:
                        st.warning(f"âš ï¸ {len(warning_issues)}ê°œì˜ ê²½ê³ ê°€ ìˆìŠµë‹ˆë‹¤:")
                        for issue in warning_issues:
                            st.write(f"- í–‰ {issue['row']}: [{issue['type']}] {issue['message']}")
                
                # 5ë‹¨ê³„: ì¤‘ë³µ ê²€ì‚¬
                if processed_questions and not error_issues:
                    st.header("5ï¸âƒ£ ì¤‘ë³µ ë¬¸ì œ ê²€ì‚¬")
                    
                    duplicate_ids = uploader.compare_with_existing(processed_questions)
                    
                    if duplicate_ids:
                        st.warning(f"âš ï¸ {len(duplicate_ids)}ê°œì˜ ì¤‘ë³µ ë¬¸ì œ IDê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
                        for dup_id in duplicate_ids:
                            st.write(f"- {dup_id}")
                        
                        replace_duplicates = st.checkbox("ì¤‘ë³µ ë¬¸ì œë¥¼ ìƒˆ ë¬¸ì œë¡œ êµì²´")
                        if not replace_duplicates:
                            st.info("ì¤‘ë³µ ë¬¸ì œë¥¼ ì œì™¸í•˜ê³  ì§„í–‰í•˜ì‹œë ¤ë©´ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                    else:
                        st.success("âœ… ì¤‘ë³µ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # 6ë‹¨ê³„: ìµœì¢… ì €ì¥
                    if not error_issues:
                        st.header("6ï¸âƒ£ ì•ˆì „í•œ ì €ì¥")
                        
                        # ë°±ì—… ìƒì„±
                        backup_file = uploader.create_backup()
                        if backup_file:
                            st.info(f"ğŸ’¾ ê¸°ì¡´ ë°ì´í„° ë°±ì—… ìƒì„±: {backup_file}")
                        
                        # ì €ì¥ ì˜µì…˜
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if st.button("ğŸ’¾ ì•ˆì „í•˜ê²Œ ì €ì¥", type="primary"):
                                # ì‹¤ì œ ì €ì¥ ë¡œì§
                                try:
                                    # ê¸°ì¡´ DB ë¡œë“œ
                                    try:
                                        with open("real_past_questions_db.json", 'r', encoding='utf-8') as f:
                                            db_data = json.load(f)
                                    except FileNotFoundError:
                                        db_data = {
                                            "metadata": {
                                                "exam_name": "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬",
                                                "total_questions": 0,
                                                "categories": ["ì†Œí”„íŠ¸ì›¨ì–´ì„¤ê³„", "ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ", "ë°ì´í„°ë² ì´ìŠ¤êµ¬ì¶•", "í”„ë¡œê·¸ë˜ë°ì–¸ì–´í™œìš©", "ì •ë³´ì‹œìŠ¤í…œêµ¬ì¶•ê´€ë¦¬"],
                                                "difficulty_levels": ["í•˜", "ì¤‘", "ìƒ"],
                                                "last_updated": datetime.now().strftime("%Y-%m-%d")
                                            },
                                            "questions": []
                                        }
                                    
                                    # ì¤‘ë³µ ì²˜ë¦¬
                                    if duplicate_ids and 'replace_duplicates' in locals() and replace_duplicates:
                                        # ì¤‘ë³µ ë¬¸ì œ ì œê±°
                                        db_data["questions"] = [q for q in db_data["questions"] if q["id"] not in duplicate_ids]
                                    elif duplicate_ids:
                                        # ì¤‘ë³µ ë¬¸ì œ ì œì™¸
                                        processed_questions = [q for q in processed_questions if q["id"] not in duplicate_ids]
                                    
                                    # ìƒˆ ë¬¸ì œë“¤ ì¶”ê°€
                                    db_data["questions"].extend(processed_questions)
                                    db_data["metadata"]["total_questions"] = len(db_data["questions"])
                                    db_data["metadata"]["last_updated"] = datetime.now().strftime("%Y-%m-%d")
                                    
                                    # ì €ì¥
                                    with open("real_past_questions_db.json", 'w', encoding='utf-8') as f:
                                        json.dump(db_data, f, ensure_ascii=False, indent=2)
                                    
                                    st.success(f"ğŸ‰ {len(processed_questions)}ê°œì˜ ë¬¸ì œê°€ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                    st.balloons()
                                    
                                    # ì €ì¥ ë¡œê·¸
                                    st.info(f"""
                                    **ì €ì¥ ì™„ë£Œ ì •ë³´:**
                                    - ì—…ë¡œë“œëœ ë¬¸ì œ: {len(processed_questions)}ê°œ
                                    - ì´ ë°ì´í„°ë² ì´ìŠ¤ ë¬¸ì œ: {len(db_data['questions'])}ê°œ
                                    - ë°±ì—… íŒŒì¼: {backup_file if backup_file else 'ì—†ìŒ'}
                                    - ì €ì¥ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                                    """)
                                
                                except Exception as e:
                                    st.error(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        
                        with col2:
                            if st.button("ğŸ“Š ë¯¸ë¦¬ë³´ê¸°ë§Œ"):
                                st.info("ì €ì¥í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.")
                                
                                # ì²˜ë¦¬ëœ ë¬¸ì œë“¤ ë¯¸ë¦¬ë³´ê¸°
                                st.subheader("ì²˜ë¦¬ëœ ë¬¸ì œ ë¯¸ë¦¬ë³´ê¸°")
                                for i, q in enumerate(processed_questions[:3]):
                                    with st.expander(f"ë¬¸ì œ {i+1}: {q['id']}"):
                                        st.write(f"**ë¬¸ì œ**: {q['question']}")
                                        for j, opt in enumerate(q['options']):
                                            if j == q['correct_answer']:
                                                st.success(f"âœ… {j+1}. {opt}")
                                            else:
                                                st.write(f"{j+1}. {opt}")
                                        st.info(f"**í•´ì„¤**: {q['explanation']}")
                
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()